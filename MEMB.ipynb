{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b8d4b91b-9f73-4097-82bd-76dcc2f8f63c",
   "metadata": {},
   "source": [
    "<h1> Maximum Excluded Mass Burning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35f70bb3-15ee-4f4b-b41b-20077863e914",
   "metadata": {},
   "source": [
    "The Maximum Excluded Mass Burning (MEMB) algorithm [1] calculates the box-covering for a given network as follows:\n",
    "\n",
    "1. Initially, mark all nodes as uncovered and non-centres.\n",
    "2. For each non-centre node calculate the excluded mass. The excluded mass is defined as the number of uncovered nodes within a radius $r_B$ of the node.\n",
    "3. Let the node with the maximum excluded mass be $p$, let $p$ be a centre and let all nodes within a radius $r_B$ from $p$ be covered.\n",
    "4. Repeat steps 2 and 3 until all nodes in the network are covered. \n",
    "\n",
    "The code in this notebook calculates the box-covering according to the MEMB algorithm as well as an amended accelerated method. It also finds the renormalised graphs under $\\ell_B$ box renormalisation and can identify if a network has fractal properties."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ad425e8-a53c-4047-9654-5937c58f2c3d",
   "metadata": {},
   "source": [
    "<h2> 1. Introduction "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dacd2713-db24-4563-884b-4ea9e827e75c",
   "metadata": {
    "tags": []
   },
   "source": [
    "<h2> Module Imports <a class=\"anchor\" id=\"module-imports\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "343b7c8c-09cc-49a6-a132-0a0045647636",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import time\n",
    "from operator import itemgetter\n",
    "from scipy.io import mmread\n",
    "import numpy as np\n",
    "import statistics\n",
    "import random\n",
    "import numpy as np\n",
    "import scipy.stats\n",
    "import math"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ceb8cc1e-b3e5-4129-b28f-518b02ccecd5",
   "metadata": {},
   "source": [
    "<H1> Workspace <a class=\"anchor\" id=\"workspace\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbfe586e-33d4-42f9-bbd2-3cca78bd807e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "eduG = read_mtx_graph_format(\"web-edu.mtx\")\n",
    "notredameG = nx.read_gml(\"web-NotreDame.gml\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d87eb1e4-ca91-4c85-aae2-5d046e63304f",
   "metadata": {},
   "source": [
    "<h2> Results <a class=\"anchor\" id=\"results\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c19731a-0940-4a25-b81f-e84c12b89a08",
   "metadata": {},
   "source": [
    "<h3>$(2,3)$-flower"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2eb1df7-c224-4c42-841c-67d193e4115e",
   "metadata": {},
   "source": [
    "3 iterations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7859d43a-57c7-481b-8611-cfdbb716aa6b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# (3,2)-flower 3 Iterations\n",
    "lB = [1, 3, 5, 7, 9, 11, 13, 15, 17, 19, 21, 23, 25, 27, 29, 31]\n",
    "NB = [470, 95, 45, 20, 20, 10, 10, 6, 5, 5, 5, 4, 3, 2, 2, 2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6603c752-9639-4a1e-aec1-ec1811b8afc5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "plot_lB_NB(lB, NB)\n",
    "plot_loglog_lB_NB(lB, NB)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93536fc7-0e59-43f4-aa5c-d8302eff90d4",
   "metadata": {},
   "source": [
    "<h3> $(1,3)$-flower"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bee71b21-6fc1-4350-8728-a775d8df0149",
   "metadata": {},
   "source": [
    "4 iterations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db400e17-b718-41dd-82d0-4198cda3ce53",
   "metadata": {},
   "outputs": [],
   "source": [
    "# (3, 1)-flower 4 Iterations\n",
    "lB = np.array([1, 3, 5, 7, 9, 11, 13, 15])\n",
    "NB = np.array([684, 172, 44, 12, 4, 2, 1, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f9e6255-2332-4a86-9661-34000d9de844",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "plot_lB_NB(lB, NB)\n",
    "plot_loglog_lB_NB(lB, NB)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea283147-62ed-4e64-aa17-4a47c5ee5fbe",
   "metadata": {},
   "source": [
    "<h3> Web Networks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb273cf3-db8d-4aa3-aa24-16c3e21535af",
   "metadata": {
    "tags": []
   },
   "source": [
    "web-edu.mtx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3fa1ebb-ff0c-405d-94e0-01a935e83f0d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Web Edu Network\n",
    "lB = [1, 3, 5, 7, 9, 11, 13]\n",
    "NB = [3031, 249, 12, 6, 3, 2, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfeda000-347d-4463-8617-be3d96d459eb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "best_exp_fit, best_exp_score = find_best_fit_iteratively(lB, NB, find_best_exp_fit, linspace_N=100)\n",
    "print(best_exp_fit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8d0ce5a-a05d-4eb7-b675-8ca0c2f8ca89",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "best_frac_fit, best_frac_score = find_best_fit_iteratively(lB, NB, find_best_fractal_fit, linspace_N=100)\n",
    "print(best_frac_fit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f81b8681-ca2c-4507-8a08-0580e2d45907",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "find_best_fractal_fit(lB, NB, A_min=0, A_max=5000, c_min=0, c_max=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e278da46-f5aa-4a60-9407-d359ef6c6556",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "plot_best_fit_comparison(lB, NB, best_exp_fit[0], best_exp_fit[1], best_frac_fit[0], best_frac_fit[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70a64a77-9656-42b4-9b5f-3bf34ff1d7b3",
   "metadata": {
    "tags": []
   },
   "source": [
    "web-NotreDame.gml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11378a98-d066-4c7d-a763-0b6daef9c510",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "G=nx.read_gml(\"32flower5iter.gml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41eefdcc-870a-4318-8ace-850a17f6d3bf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(len(G.nodes()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de05bf55-326b-4892-82e6-e0b852976cae",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "G = nx.read_gml(\"32flower3iter.gml\")\n",
    "print(len(G.nodes()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e317787-bdbe-4b73-bc67-53025f6f3859",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "current_graph = G.copy()\n",
    "lB = 3\n",
    "count = 1\n",
    "while len(list(current_graph.nodes())) > 1:\n",
    "    new_graph = main(current_graph, lB, count)\n",
    "    current_graph = new_graph.copy()\n",
    "    count += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a55da77a-f3ce-4338-80ce-5c1748bc380c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "box_mass = [14, 12, 12, 14, 14, 6, 8, 7, 6, 6, 8, 7, 5, 7, 6, 8, 7, 8, 8, 9, 4, 4, 4, 5, 4, 4, 4, 4, 5, 5, 3, 4, 4, 4, 3, 4, 4, 3, 4, 4, 4, 4, 3, 3, 5, 5, 5, 4, 4, 5, 4, 4, 4, 4, 5, 5, 4, 3, 3, 3, 4, 3, 4, 3, 4, 4, 5, 4, 5, 3, 3, 3, 3, 5, 4, 4, 3, 4, 3, 4, 4, 5, 3, 4, 3, 5, 4, 4, 5, 5, 4, 4, 5, 3, 4]\n",
    "box_avg = sum(box_mass)/len(box_mass)\n",
    "print(box_avg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca555947-2a04-4f4c-b9b9-d546d7ac6573",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "box_mass = [7, 6, 7, 6, 7, 4, 4, 4, 4, 5, 5, 3, 4, 3, 4, 4, 5, 4, 4, 5]\n",
    "box_avg = sum(box_mass)/len(box_mass)\n",
    "print(box_avg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56ce89a4-74e4-443b-afd1-d78ac527d4c1",
   "metadata": {},
   "source": [
    "<h1> Functions <a class=\"anchor\" id=\"functions\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bb9c6c8-74f2-4558-ad11-5e01d5c29cb3",
   "metadata": {},
   "source": [
    "<h2> Read Graphs <a class=\"anchor\" id=\"read\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fb9bb85-3933-4b0d-b0c9-a9d2a27bc880",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def read_mtx_graph_format(filepath):\n",
    "    \"\"\"\n",
    "    Reads graphs stored in the .mtx file format. Use with, for example, graphs from www.networkrepository.com.\n",
    "    Note: Some files may need to be edited to make sure that scipy.io can read them. Files should have a header starting with %%MatrixMarket and a single line denoted the number of values in each column. \n",
    "    \n",
    "    Args:\n",
    "        filepath (str): Filepath to .mtx file\n",
    "        \n",
    "    Returns:\n",
    "        G (networkx.Graph): Network read from file. \n",
    "    \"\"\"\n",
    "    # Read the file using the scipy.io file reader. \n",
    "    mmf = mmread(filepath)\n",
    "    # Generate a graph from this file. \n",
    "    G = nx.from_scipy_sparse_array(mmf)\n",
    "    # Return the graph.\n",
    "    return G"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10480cf5-1b1c-4cf3-867d-50dfd21e3444",
   "metadata": {},
   "source": [
    "<h2> Maximal Excluded Mass Burning <a class=\"anchor\" id=\"MEMB\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ebf11f5-edcd-4f95-ae67-14d02949c970",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def MEMB(G, lB, deterministic=True):\n",
    "    \"\"\"\n",
    "    Implements the Maximal Excluded Mass Burning algorithm as according to [1].\n",
    "    Note: Only works for odd numbers!\n",
    "    \n",
    "    Args: \n",
    "        G (networkx.Graph): The network the algorithm is to be applied to. \n",
    "        lB (int): The diameter of the boxes used to cover the network.\n",
    "        deterministic (Bool) (opt): If False, choose fom nodes with equal excluded mass randomly. If True, choose the first lexicographically.\n",
    "    \n",
    "    Returns: \n",
    "        centres (list): A list of nodes assigned to be centres under the MEMB algorithm. \n",
    "    \"\"\"\n",
    "    # Start with all nodes being uncovered and non-centres. \n",
    "    uncovered = list(G.nodes())\n",
    "    non_centres = list(G.nodes())\n",
    "    \n",
    "    # Initialise empty lists for the covered and centre nodes. \n",
    "    covered = []\n",
    "    centres = []\n",
    "    \n",
    "    # Each box can have diameter of up to lB, so the maximum radius is rB = (lB-1)/2.\n",
    "    rB = (lB-1)/2\n",
    "    \n",
    "    # Initialise an empty dictionary to store nodes and a list of nodes in the graphs centred on these nodes with a radius rB.\n",
    "    # Doing this stops us from having to generate the same subgraphs multiple times, which is expensive. \n",
    "    eg_dict = {}\n",
    "    \n",
    "    # For each node find the graph centres on that node with radius rB. \n",
    "    for node in G.nodes():\n",
    "        H = nx.ego_graph(G, node, radius=rB)\n",
    "        eg_dict[node] = list(H.nodes()) # Add the list of nodes in that graph to the dictionary.\n",
    "\n",
    "    # Iterate while there are still nodes uncovered in the graph.\n",
    "    while len(uncovered) > 0:\n",
    "\n",
    "        # Start with a maximum excluded mass of zero, and no node p [1].\n",
    "        p = None\n",
    "        maximum_excluded_mass = 0\n",
    "        \n",
    "        # For the non-deterministic method, keep a list of nodes with equal maximum excluded mass \n",
    "        possible_p = []\n",
    "\n",
    "        # For each node that isn't a centre, find the excluded mass.\n",
    "        for node in non_centres:\n",
    "            # The excluded mass is the number of uncovered nodes in within a radius of rB.\n",
    "            excluded_mass = len(list(set(eg_dict[node])-set(covered)))\n",
    "            # If the excluded mass of this node is greater than the current excluded mass, choose this node.\n",
    "            if excluded_mass > maximum_excluded_mass:\n",
    "                p = node # Update p.\n",
    "                maximum_excluded_mass = excluded_mass # Update maximum excluded mass.\n",
    "                possible_p = [node] # Update list of possible nodes for non-deterministic method.\n",
    "            # If the excluded mass of this node is equal to the current maximum excluded mass, then add this node to the list of possible p.\n",
    "            elif excluded_mass == maximum_excluded_mass:\n",
    "                possible_p.append(node)\n",
    "        \n",
    "        # If the non-deterministic method is chosen, then randomly choose a node from the list of possible p.\n",
    "        if not deterministic:\n",
    "            p = random.choice(possible_p)\n",
    "                \n",
    "        # Add the chosen p to the list of centres. \n",
    "        centres.append(p)\n",
    "        # Remove the chosen p from the list of non-centres.\n",
    "        non_centres.remove(p)\n",
    "\n",
    "        # Find the graph centred on the node p with radius rB.\n",
    "        H = eg_dict[p] \n",
    "        # Iterate through the nodes in this subgraph.\n",
    "        for node in H:\n",
    "            covered.append(node) # Cover the nodes in the subgraph.\n",
    "            # Remove these nodes from the list of uncovered nodes.\n",
    "            if node in uncovered:\n",
    "                uncovered.remove(node)        \n",
    "    \n",
    "    # Once all the nodes are covered, return the list of centres. \n",
    "    return centres\n",
    "    \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "329ff81a-e901-4272-8b40-7e46602d936e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def degree_based_MEMB(G, lB, deterministic=True, N=10):\n",
    "    \"\"\"\n",
    "    Implements the Maximal Excluded Mass Burning algorithm as according to [1], adjusted to prioritise nodes with high degree. \n",
    "    This reduces the running time of the traditional MEMB without losing accuracy.\n",
    "    Note: Only works for odd numbers!\n",
    "    \n",
    "    Args: \n",
    "        G (networkx.Graph): The network the algorithm is to be applied to. \n",
    "        lB (int): The diameter of the boxes used to cover the network.\n",
    "        deterministic (Bool) (opt): If False, choose fom nodes with equal excluded mass randomly. If True, choose the first lexicographically.\n",
    "        N (int): Takes the top N-th nodes by degree to find the centred subgraph of. \n",
    "    \n",
    "    Returns: \n",
    "        centres (list): A list of nodes assigned to be centres under the MEMB algorithm. \n",
    "    \"\"\"\n",
    "    \n",
    "    # If the diameter lB is less than or equal to 2, then the maximum radius is 0 and so every node is in its own box.\n",
    "    if lB == 1 or lB == 2:\n",
    "        return list(G.nodes())\n",
    "    \n",
    "    # Start with all nodes being uncovered and non-centres. \n",
    "    uncovered = list(G.nodes())\n",
    "    \n",
    "    # Initialise empty lists for the covered and centre nodes. \n",
    "    covered = []\n",
    "    centres = []\n",
    "    \n",
    "    # Each box can have diameter of up to lB, so the maximum radius is rB = (lB-1)/2.\n",
    "    rB = (lB-1)/2\n",
    "\n",
    "    # Find the N nodes with the greatest degree centrality. \n",
    "    dc = nx.degree_centrality(G)\n",
    "    top_N_dc = dict(sorted(dc.items(), key=itemgetter(1), reverse=True)[:N])\n",
    "\n",
    "    # Initialise an empty dictionary to store nodes and a list of nodes in the graphs centred on these nodes with a radius rB.\n",
    "    # Doing this stops us from having to generate the same subgraphs multiple times, which is expensive. \n",
    "    eg_dict = {}\n",
    "    for node in top_N_dc:\n",
    "        H = nx.ego_graph(G, node, radius=rB)\n",
    "        eg_dict[node] = list(H.nodes())\n",
    "    \n",
    "    # On the initial iteration, set maiden to True.\n",
    "    maiden = True\n",
    "    \n",
    "    # This variable checks if the algorithm does not find a solution, and then looks at the next N nodes. \n",
    "    failed = False\n",
    "    \n",
    "    # Iterate while there are still nodes uncovered in the graph.\n",
    "    while len(uncovered) > 0:\n",
    "        \n",
    "        # For all iterations except the first, calculate the new dictionary of nodes in each subgraph of radius rB.\n",
    "        if not maiden:\n",
    "            eg_dict = calc_next_iter(G, uncovered, N, dc, eg_dict, rB, centres, p, failed)\n",
    "        maiden = False\n",
    "\n",
    "        # Start with a maximum excluded mass of zero, and no node p [1].\n",
    "        p = None\n",
    "        maximum_excluded_mass = 0\n",
    "        \n",
    "        # For the non-deterministic method, keep a list of nodes with equal maximum excluded mass \n",
    "        possible_p = []\n",
    "        \n",
    "        # For each of the top N nodes by degree, find the excluded mass. \n",
    "        for node in eg_dict:\n",
    "            # The excluded mass is the number of uncovered nodes in within a radius of rB. \n",
    "            excluded_mass = len(list(set(eg_dict[node])-set(covered)))\n",
    "            # If the excluded mass of this node is greater than the current excluded mass, choose this node.\n",
    "            if excluded_mass > maximum_excluded_mass:\n",
    "                p = node # Update p.\n",
    "                maximum_excluded_mass = excluded_mass # Update maximum excluded mass. \n",
    "                possible_p = [node] # Update list of possible nodes for non-deterministic method.\n",
    "            # If the excluded mass of this node is equal to the current maximum excluded mass, then add this node to the list of possible p.\n",
    "            elif excluded_mass == maximum_excluded_mass:\n",
    "                possible_p.append(node)\n",
    "            \n",
    "        # If the non-deterministic method is chosen, then randomly choose a node from the list of possible p.\n",
    "        if not deterministic:\n",
    "            p = random.choice(possible_p)\n",
    "        \n",
    "        # Check if the method fails to find a node p. \n",
    "        # The method only fails if every single node has zero uncovered nodes within a radius rB. \n",
    "        if p == None:\n",
    "            # If it does fail, remove all the nodes that have already been tried from the list of top N nodes. \n",
    "            failed=True # Set the failed variable.\n",
    "            for tried_node in eg_dict:\n",
    "                dc.pop(tried_node)\n",
    "        else:    \n",
    "            # Otherwise, add the new p to the list of centre nodes. \n",
    "            centres.append(p)\n",
    "            # Update the list so that the newly covered nodes are in the list of covered nodes and not in the list of uncovered nodes. \n",
    "            for node in eg_dict[p]:\n",
    "                if node in uncovered:\n",
    "                    uncovered.remove(node)\n",
    "                    covered.append(node)\n",
    "            failed=False # Reset the failed variable.\n",
    "\n",
    "    # Once all the nodes are covered return the list of centres found in the graph.\n",
    "    return centres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c8c50d9-1520-4ac1-b951-5ec29a6cc114",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def calc_next_iter(G, uncovered,  N, dc, eg_dict, rB, centres, p, failed):\n",
    "    \"\"\"\n",
    "    Finds the top N nodes to check in the next iteration of the algorithm.\n",
    "    \n",
    "    Args:\n",
    "        G (networkx.Graph): The network being analysed. \n",
    "        uncovered (list): A list of nodes in the network which are uncovered at this stage.\n",
    "        N (int): The number of nodes to check in the next iteration of the algorithm.\n",
    "        dc (dict): Dictionary containing the degree centrality of each node which is yet to be checked as a centre.\n",
    "        eg_dict (dict): Dictionary with keys as nodes and values as the list of nodes within a distance of rB from that node.\n",
    "        rB (int): The radius rB to be checked. \n",
    "        centres (list): List of nodes identified as centres. \n",
    "        p (str): Name of the node chosen as the most recent p [1].\n",
    "        failed (Bool): True if the previous iteration of the algorithm failed, and False otherwise. \n",
    "    \n",
    "    Returns:\n",
    "        eg_dict (dict): Returns an updated version of eg_dict with the nodes to be checked for the next iteration. \n",
    "    \"\"\"\n",
    "    \n",
    "    # If the algorithm failed in the previous iteration, then remove the most recent node p from the dictionary. \n",
    "    # This node was chosen as a centre in the last stage, and so it does not need to be considered again.\n",
    "    if not failed:\n",
    "        dc.pop(p)\n",
    "        \n",
    "    # Choose the top N nodes by degree centrality. \n",
    "    top_N_dc = dict(sorted(dc.items(), key=itemgetter(1), reverse=True)[:N])\n",
    "    \n",
    "    # Initialise an empty updated version of eg_dict.\n",
    "    new_eg_dict = {}\n",
    "\n",
    "    # For each of the top N nodes, assign the list of nodes in the subgraph of radius rB centred around the node to the new dictionary.\n",
    "    for node in top_N_dc:\n",
    "        # If the subgraph has already been found then reference the old dictionary to prevent recalculating the subgraph.\n",
    "        if node in eg_dict:\n",
    "            new_eg_dict[node] = eg_dict[node]\n",
    "        # If not, then find the graph and add it to the new dictionary.\n",
    "        else:\n",
    "            H = nx.ego_graph(G, node, radius=rB)\n",
    "            new_eg_dict[node] = list(H.nodes())\n",
    "    \n",
    "    # Once this is done for all the relevant nodes, return the new updated dictionary.\n",
    "    return new_eg_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16e089e1-3357-4b24-992c-78aede16747f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def original_method(G, lB):\n",
    "    N = len(G.nodes())\n",
    "    start = time.time()\n",
    "    new_centres = MEMB(G,lB)\n",
    "    print(new_centres)\n",
    "    end = time.time()\n",
    "    print(len(new_centres))\n",
    "    print(end-start)\n",
    "    #[2939, 2940, 2943]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f908a9a6-dd56-4473-8697-3e0d77599436",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def degree_method(G, lB):\n",
    "    N = len(G.nodes())\n",
    "    start = time.time()\n",
    "    db_centres = degree_based_MEMB(G,lB,egoN=500)\n",
    "    print(db_centres)\n",
    "    end = time.time()\n",
    "    print(len(db_centres))\n",
    "    print(end-start)\n",
    "    #[2939, 2940, 2943]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "531f5c85-7d09-4b05-bc7b-1de31622424c",
   "metadata": {},
   "source": [
    "<h2> Find Best Fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bb24a02-878a-4e42-8719-9e72bc4f2cd3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def sum_of_squares_deviation(y, est_y):\n",
    "    sum_of_squares = 0\n",
    "    for (yi, est_yi) in zip(y, est_y):\n",
    "        sum_of_squares += (est_yi - yi) ** 2\n",
    "    return sum_of_squares"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df0545b6-27fa-43ae-a995-31f6f1955dc0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def find_best_exp_fit(x, y, A_min=0, A_max=100, c_min=0, c_max=2, linspace_N=100):\n",
    "    \"\"\"\n",
    "    Finds the best exponential fit according to the sum of squares deviation of the form y = Ae^{cx}\n",
    "    \"\"\"\n",
    "    best_fit = (None, None)\n",
    "    best_score = None\n",
    "    for A in np.linspace(A_min, A_max, linspace_N):\n",
    "        for c in np.linspace(c_min, c_max, linspace_N):\n",
    "            est_y = [A * math.e ** (-c*i) for i in lB]\n",
    "            score = sum_of_squares_deviation(y, est_y)\n",
    "            if best_score == None:\n",
    "                best_score = score\n",
    "                best_fit = (A, c)\n",
    "            elif score < best_score:\n",
    "                best_score = score\n",
    "                best_fit = (A, c)\n",
    "    return best_fit, best_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c2145af-d7f9-4e18-b4a4-cef40447cd73",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def find_best_fractal_fit(x, y, A_min=0, A_max=100, c_min = 0, c_max = 2, linspace_N=100):\n",
    "    \"\"\"\n",
    "    Finds the best exponential fit according to the sum of squares deviation of the form y = Ax^{-c}\n",
    "    \"\"\"\n",
    "    best_fit = (None, None)\n",
    "    best_score = None\n",
    "    for A in np.linspace(A_min, A_max, 100):\n",
    "        for c in np.linspace(c_min, c_max, 100):\n",
    "            est_y = [A * i ** (-c) for i in lB]\n",
    "            score = sum_of_squares_deviation(y, est_y)\n",
    "            if best_score == None:\n",
    "                best_score = score\n",
    "                best_fit = (A, c)\n",
    "            elif score < best_score:\n",
    "                best_score = score\n",
    "                best_fit = (A, c)\n",
    "    return best_fit, best_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1adc0f2-3107-463c-a458-d48d9df24463",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def find_best_fit_iteratively(x, y, method, linspace_N=100):\n",
    "    \n",
    "    A_min = 0\n",
    "    A_max = 10000\n",
    "    c_min = 0\n",
    "    c_max = 12.5\n",
    "    \n",
    "    A_diff = A_max - A_min\n",
    "    c_diff = c_max - c_min\n",
    "    \n",
    "    for i in range(3):\n",
    "        best_fit, best_score = method(x, y, A_min=A_min, A_max=A_max, c_min=c_min, c_max=c_max, linspace_N=linspace_N)\n",
    "        \n",
    "        A_diff = A_diff / 10\n",
    "        c_diff = c_diff / 5\n",
    "        \n",
    "        best_A_approximation = best_fit[0]\n",
    "        best_c_approximation = best_fit[1]\n",
    "        \n",
    "        A_min = max(0, best_A_approximation - (A_diff/2))\n",
    "        A_max = best_A_approximation + (A_diff/2)\n",
    "        c_min = max(0, best_c_approximation - (c_diff/2))\n",
    "        c_max = best_c_approximation + (c_diff/2)\n",
    "\n",
    "    return best_fit, best_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9483c810-26b2-4810-adb7-0a1c7437d352",
   "metadata": {},
   "source": [
    "<h2> Plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1771673-e14a-44ca-8823-0a24deea7674",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def plot_best_fit_comparison(lB, NB, exp_A, exp_c, frac_A, frac_c):\n",
    "    lB = np.array(lB)\n",
    "    NB = np.array(NB)\n",
    "    \n",
    "    est_NB_exp = [exp_A * math.e ** (-exp_c*i) for i in lB]\n",
    "    est_NB_frac = [frac_A * i ** (-frac_c) for i in lB]\n",
    "    \n",
    "    fig, axes = plt.subplots(nrows=1, ncols=2, figsize=(10, 3))\n",
    "    axes[0].plot(lB, NB, color='#000066', label=\"Empirical Data\")\n",
    "    axes[0].plot(lB, est_NB_exp, color='#C00000', label=\"Best Fit\")\n",
    "    axes[1].plot(lB, NB, color='#000066')\n",
    "    axes[1].plot(lB, est_NB_frac, color='#C00000')\n",
    "\n",
    "    fig.suptitle('Non-Fractal Network Model', fontsize=16)\n",
    "\n",
    "    axes[0].set_xlabel('$\\ell_B$')\n",
    "    axes[0].set_title('Exponential Relation')\n",
    "    axes[0].set_ylabel('$N_B$')\n",
    "    axes[0].text(12, 600, r\"$SSR \\approx 6.367$\")\n",
    "\n",
    "    axes[1].set_xlabel('$\\ell_B$')\n",
    "    axes[1].set_title('Power-Law Relation')\n",
    "    axes[1].set_ylabel('$N_B$')\n",
    "    axes[1].text(12, 600, r\"$SSR \\approx 3566$\")\n",
    "\n",
    "    fig.legend(loc=\"upper left\")\n",
    "    fig.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96ff17b5-c69a-4a42-b174-365fffeb160c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def plot_lB_NB(lB, NB):\n",
    "    plt.plot(lB, NB, color='#C00000')\n",
    "    plt.xlabel('$\\ell_B$')\n",
    "    plt.ylabel('$N_B$')\n",
    "    plt.title('The optimal number of boxes $N_B$ against the diameter $\\ell_B$.')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "832d2010-b500-4c76-a43c-2a5c84aee67a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def plot_loglog_lB_NB(lB, NB):\n",
    "    plt.loglog(lB, NB, color='#C00000')\n",
    "    plt.xlabel('$\\ell_B$')\n",
    "    plt.ylabel('$N_B$')\n",
    "    plt.title('The optimal number of boxes $N_B$ against the diameter $\\ell_B$.')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9db18a5-9ac1-4050-81ac-6470c6790d85",
   "metadata": {},
   "source": [
    "<h2> Finding Boxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91604519-cbc2-40f6-b9fe-ae79ab459417",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def find_central_distance(G, centres):\n",
    "    central_distance = {}\n",
    "    for v in list(G.nodes()):\n",
    "        shortest_path_len = None\n",
    "        closest_neighbour = None\n",
    "        for u in centres:\n",
    "            path_len = nx.shortest_path_length(G, v, u)\n",
    "            if shortest_path_len == None or shortest_path_len > path_len:\n",
    "                shortest_path_len = path_len\n",
    "                closest_neighbour = u\n",
    "        central_distance[v] = shortest_path_len\n",
    "    return central_distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7f32fd7-5cb0-4adb-841f-dbe7be1bac70",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def assign_nodes_to_boxes(G, centres, central_distance):\n",
    "    # TO DO REDO VARIABLE NAMING HERE\n",
    "    boxes = {}\n",
    "    nodes = list(G.nodes())\n",
    "    non_centres = list(set(nodes) - set(centres))\n",
    "    \n",
    "    sorted_non_centres = []\n",
    "    sorted_dict = dict(sorted(central_distance.items(), key=itemgetter(1)))\n",
    "    for key in sorted_dict:\n",
    "        if not key in centres:\n",
    "            sorted_non_centres.append(key)\n",
    "\n",
    "    id = 0\n",
    "    for node in centres:\n",
    "        boxes[node] = id\n",
    "        id += 1\n",
    "    for node in sorted_non_centres:\n",
    "        possible_boxes = []\n",
    "        for neighbour in G.neighbors(node):\n",
    "            if central_distance[node] > central_distance[neighbour]:\n",
    "                possible_boxes.append(boxes[neighbour])\n",
    "        boxes[node] = random.choice(possible_boxes)\n",
    "    return boxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0f98045-331f-44a7-919a-881c52bd7de2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def find_boxes(nodes_to_boxes, centres):\n",
    "    \"\"\"\n",
    "    Finds a list of nodes assigned to each box in a network.\n",
    "    \n",
    "    Args:\n",
    "        nodes_to_boxes (dict): A dictionary with nodes as keys and their corresponding boxes as values. \n",
    "        centres (list): A list of the nodes found as centres under the MEMB algorithm. \n",
    "    \n",
    "    Returns:\n",
    "        boxes (dict): A dictionary with boxes as keys and a list of nodes in that box as the value. \n",
    "    \"\"\"\n",
    "    # Initialise an empty dictionary to store the boxes.\n",
    "    boxes = {}\n",
    "    # The box IDs are 0, ..., k-1 where k is the number of centres. \n",
    "    for i in range(len(centres)): # Iterate over the box IDs.\n",
    "        # Initialise an empty list of nodes.\n",
    "        nodes = []\n",
    "        # Check if each node belongs in the current box.\n",
    "        for node in nodes_to_boxes:\n",
    "            # If it does, add it to the list of nodes.\n",
    "            if nodes_to_boxes[node] == i:\n",
    "                nodes.append(node)\n",
    "        # Assign the list of nodes to the box. \n",
    "        boxes[i] = nodes\n",
    "    # Return the dictionary of boxes to nodes. \n",
    "    return boxes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d5f2f51-8875-48c0-8f26-2df9d84eb38a",
   "metadata": {},
   "source": [
    "<h1> Renormalised Graph\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d1feeb4-b6a6-475a-9f0b-bfc803a38aaf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def renormalise_graph(G, boxes, nodes_to_boxes):\n",
    "    renormalisedG = nx.Graph()\n",
    "    for box in boxes:\n",
    "        renormalisedG.add_node(box)\n",
    "    for edge in G.edges():\n",
    "        source = edge[0]\n",
    "        target = edge[1]\n",
    "        renormalised_source = nodes_to_boxes[source]\n",
    "        renormalised_target = nodes_to_boxes[target]\n",
    "        renormalisedG.add_edge(renormalised_source, renormalised_target)\n",
    "    renormalisedG.remove_edges_from(nx.selfloop_edges(renormalisedG))\n",
    "    nx.draw_kamada_kawai(renormalisedG, node_color = list(renormalisedG.nodes()))\n",
    "    return renormalisedG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ceeed1d-8d94-4f15-8f90-f308d276934f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def main(G, lB, count=1):\n",
    "\n",
    "    centres = degree_based_MEMB(G, lB, deterministic=True, N=10)\n",
    "    central_distance = find_central_distance(G, centres)\n",
    "    nodes_to_boxes = assign_nodes_to_boxes(G, centres, central_distance)\n",
    "    colourmap = []\n",
    "    for node in G.nodes():\n",
    "        colourmap.append(nodes_to_boxes[node])\n",
    "    plt.figure(1)\n",
    "    nx.draw_kamada_kawai(G, node_color = colourmap)\n",
    "    boxes = find_boxes(nodes_to_boxes, centres)\n",
    "    \n",
    "    print(\"Iteration {0}\".format(count))\n",
    "    box_sizes = []\n",
    "    for box in boxes:\n",
    "        box_sizes.append(len(boxes[box]))\n",
    "    print(len(G.nodes()), box_sizes)\n",
    "    \n",
    "    boxes_file_path = \"32flower5iter_boxes_\" + str(count)\n",
    "    renormalised_file_path = \"32flower5iter_renormalised_\" + str(count)\n",
    "    \n",
    "    export_to_gephi(G, nodes_to_boxes, boxes_file_path)\n",
    "    plt.figure(2)\n",
    "    renormalisedG = renormalise_graph(G, boxes, nodes_to_boxes)\n",
    "    gephi_dict = {}\n",
    "    for node in renormalisedG:\n",
    "        gephi_dict[node] = node\n",
    "    \n",
    "    export_to_gephi(renormalisedG, gephi_dict, renormalised_file_path)\n",
    "    plt.show()\n",
    "    return renormalisedG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "156b4ac3-5238-4a92-b691-3ea151e53e9b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#H = nx.watts_strogatz_graph(100, 4,0.7)\n",
    "eduG = read_mtx_graph_format(\"web-edu.mtx\")\n",
    "current_graph = eduG.copy()\n",
    "lB = 3\n",
    "count = 1\n",
    "while len(list(current_graph.nodes())) > 1:\n",
    "    new_graph = main(current_graph, lB, count)\n",
    "    current_graph = new_graph.copy()\n",
    "    count += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27bb471e-6b4e-4325-b02a-bfb706b47a07",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "H = nx.watts_strogatz_graph(25, 4,0.7)\n",
    "centres = degree_based_MEMB(H, 3, deterministic=True, N=10)\n",
    "central_distance = find_central_distance(H, centres)\n",
    "nodes_to_boxes = assign_nodes_to_boxes(H, centres, central_distance)\n",
    "colourmap = []\n",
    "for node in H.nodes():\n",
    "    colourmap.append(nodes_to_boxes[node])\n",
    "nx.draw_kamada_kawai(H, with_labels=True, node_color = colourmap)\n",
    "boxes = find_boxes(nodes_to_boxes, centres)\n",
    "print(boxes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "606db420-4f13-417a-9afa-b99f56d5693f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "renormalise_graph(H, boxes, nodes_to_boxes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "908337e8-2ad8-41be-a079-8b13a3b10d21",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def export_to_gephi(G, nodes_to_boxes, file_path):\n",
    "    H = G.copy()\n",
    "    nx.set_node_attributes(H, nodes_to_boxes, 'boxes')\n",
    "    nx.write_graphml(H, file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ce8eff5-5c11-4fba-aac7-792611e0d2f0",
   "metadata": {},
   "source": [
    "<h1> References"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74f5da5b-7617-4956-8089-d22a58a15e2c",
   "metadata": {},
   "source": [
    "[1] C. Song, L. K. Gallos, S. Havlin, and H. A. Makse, “How to calculate the fractal dimension of a complex\n",
    "network: The box covering algorithm,” Journal of Statistical Mechanics, 2007."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dd6ae4d-23b5-4347-ad37-6b024e9bac66",
   "metadata": {},
   "source": [
    "<h1> Depreciated Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe0a0f4f-c877-42c7-a841-cc8196316c05",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def calculate_excluded_mass(G, covered, node, rB):\n",
    "    H = nx.ego_graph(G, node, radius=rB)\n",
    "    uncovered_size = len(list(set(H.nodes())-set(covered)))\n",
    "    #print(\"MEMB of {0} is {1}\".format(node, uncovered_size))\n",
    "    return uncovered_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74fc3a9f-fb2d-4d46-977e-b7622fc30bab",
   "metadata": {},
   "outputs": [],
   "source": [
    "def subgraph_degree_centrality(G, uncovered):\n",
    "    N = len(uncovered)\n",
    "    dc = {}\n",
    "    for node in G:\n",
    "        neighbourhood = set(list((nx.neighbors(G, node))))\n",
    "        uncovered_neighbourhood = neighbourhood.intersection(set(uncovered))\n",
    "        dc[node] = len(uncovered_neighbourhood)/N\n",
    "    return dc\n",
    "\n",
    "def subgraph_closeness_centrality(G, uncovered, top_N_dc):\n",
    "    N = len(uncovered)\n",
    "    cs_dict = {}\n",
    "    for node in top_N_dc:\n",
    "        csN = N\n",
    "        sum_d = 0\n",
    "        for uncovered_node in uncovered:\n",
    "            if node == uncovered_node:\n",
    "                csN -= 1\n",
    "            else:\n",
    "                d = nx.shortest_path_length(G, source=node, target=uncovered_node)\n",
    "                sum_d += d\n",
    "        cs_dict[node] = csN/sum_d\n",
    "    #print(cs_dict)\n",
    "    return cs_dict"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
